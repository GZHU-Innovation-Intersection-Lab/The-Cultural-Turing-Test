import os
import re
from time import sleep
from typing import List, Dict

import httpx
import pandas as pd
from openpyxl import load_workbook
from openai import OpenAI
import json


# ================= Basic Configuration =================
API_KEY = os.getenv("OPENAI_API_KEY", '')
BASE_URL = os.getenv("OPENAI_BASE_URL", 'https://api.gptsapi.net/v1')
MODEL_NAME = 'gpt-5-chat'

PROXY_ENABLED = False
HTTP_PROXY_URL = os.getenv('HTTP_PROXY_URL', 'http://127.0.0.1:7890')

# Unified persona and question files
CHARACTER_FILE = r"prompt\test1\persona1.xlsx"  # 12 Personas, take rows 1-12
QUESTION_FILE = r"prompt\prompt3.xlsx"  # 20 questions (context only, optional)

# Templates for prompt and input answer directories
PROMPT_FILE_TEMPLATE = r"prompt\test{test}\test{test}.txt"
RES_DIR_TEMPLATE = r"res\test{test}"
INPUT_ANSWERS_XLSX = r"test{test}_{model}_1.xlsx"  # Original answers generated by previous steps

# Scoring rules and requirements
SCORING_RULES_FILE = "scoring_rules.txt"      # Scoring rules
SCORING_REQUIRE_FILE = "scoring_requirements.txt"    # Scoring requirements (optional)


def create_client():
    http_client = None
    if PROXY_ENABLED:
        transport = httpx.HTTPTransport(proxy=HTTP_PROXY_URL)
        http_client = httpx.Client(transport=transport)
    client = OpenAI(api_key=API_KEY, base_url=BASE_URL, http_client=http_client)
    return client


def read_text_file(path: str) -> str:
    try:
        with open(path, 'r', encoding='utf-8') as f:
            return f.read().strip()
    except Exception:
        return ''


def read_persona(character_xlsx: str, row_index: int) -> str:
    wb = load_workbook(filename=character_xlsx)
    ws = wb.active
    value = ws.cell(row=row_index, column=1).value
    return (str(value).strip() if value is not None else '')


def read_answers(res_dir: str, test_str: str, model_name: str, row_index: int) -> List[str]:
    xlsx_path = os.path.join(res_dir, INPUT_ANSWERS_XLSX.format(test=test_str, model=model_name))
    if not os.path.exists(xlsx_path):
        return []
    df = pd.read_excel(xlsx_path)
    # Expected columns Q1..Q20
    cols = [f"Q{i}" for i in range(1, 21)]
    for c in cols:
        if c not in df.columns:
            df[c] = ''
    if row_index - 1 >= len(df):
        return []
    row = df.iloc[row_index - 1]
    return [str(row[c]) if pd.notna(row[c]) else '' for c in cols]


def build_scoring_prompt(rules_text: str, require_text: str, persona: str, prompt_text: str, qa_list: List[str]) -> List[Dict[str, str]]:
    qa_joined = "\n".join([q for q in qa_list if isinstance(q, str) and q.strip()])
    content = f"""
You are a strict and fair scorer. Please score the given persona and its answers to 20 questions based on the "Scoring Rules" and "Scoring Requirements".

=== Scoring Rules ===
{rules_text}

=== Scoring Requirements (Ignore if empty) ===
{require_text}

=== Persona ===
{persona}

=== Prompt (The persona answered under this prompt) ===
{prompt_text}

=== Answers (Q1~Q20, including selection and reasoning) ===
{qa_joined}

Please output:
1) Scores for each dimension (0-5, keep one decimal place)
2) Total score (0-25)
3) Brief reasoning (<=120 words)
4) Actionable advice (<=120 words)

Strictly use the following JSON format (no extra text):
{{
  "dimension_scores": {{"Correctness": x, "PersonaFit": x, "Consistency": x, "AffectiveTone": x, "Depth": x}},
  "total": x,
  "reason": "...",
  "advice": "..."
}}
""".strip()
    return [
        {"role": "system", "content": "You are a professional scorer. Output must be valid JSON."},
        {"role": "user", "content": content}
    ]


def call_score_api(client: OpenAI, messages: List[Dict[str, str]], max_tokens: int = 1024, temperature: float = 0.2) -> str:
    for _ in range(2):  # Retry twice
        try:
            resp = client.chat.completions.create(
                model=MODEL_NAME,
                messages=messages,
                max_tokens=max_tokens,
                temperature=temperature,
                stream=False,
                timeout=60
            )
            return resp.choices[0].message.content.strip()
        except Exception as e:
            print(f"Scoring API failed: {e}")
            sleep(3)
    return ""


def score_one_test(test_str: str):
    client = create_client()

    res_dir = RES_DIR_TEMPLATE.format(test=test_str)
    os.makedirs(res_dir, exist_ok=True)

    prompt_text = read_text_file(PROMPT_FILE_TEMPLATE.format(test=test_str))
    rules_text = read_text_file(SCORING_RULES_FILE)
    require_text = read_text_file(SCORING_REQUIRE_FILE)

    records = []

    for persona_row in range(1, 13):  # 12 Personas
        persona = read_persona(CHARACTER_FILE, persona_row)
        qa_list = read_answers(res_dir, test_str, MODEL_NAME, persona_row)
        if not qa_list:
            print(f"test{test_str} Persona {persona_row}: Original answer not found, skipping")
            continue

        messages = build_scoring_prompt(rules_text, require_text, persona, prompt_text, qa_list)
        result_text = call_score_api(client, messages)

        # Parse JSON
        parsed = {
            'Correctness': None,
            'PersonaFit': None,
            'Consistency': None,
            'AffectiveTone': None,
            'Depth': None,
            'total': None,
            'reason': '',
            'advice': ''
        }
        cleaned = result_text.strip()
        # Remove potential Markdown fences
        if cleaned.startswith('```'):
            cleaned = cleaned.strip('`')
            cleaned = cleaned.replace('json', '', 1).strip()
        try:
            obj = json.loads(cleaned)
            dims = obj.get('dimension_scores', {}) if isinstance(obj, dict) else {}
            parsed.update({
                'Correctness': dims.get('Correctness'),
                'PersonaFit': dims.get('PersonaFit'),
                'Consistency': dims.get('Consistency'),
                'AffectiveTone': dims.get('AffectiveTone'),
                'Depth': dims.get('Depth'),
                'total': obj.get('total'),
                'reason': obj.get('reason', ''),
                'advice': obj.get('advice', '')
            })
            print(f"test{test_str} Persona {persona_row}: JSON parsed successfully, Total={parsed['total']}")
        except Exception as e:
            print(f"test{test_str} Persona {persona_row}: JSON parse failed: {e}")
            print(f"Raw data: {cleaned[:200]}...")

        records.append({
            'test': f'test{test_str}',
            'persona_row': persona_row,
            'persona': persona,
            'prompt_file': PROMPT_FILE_TEMPLATE.format(test=test_str),
            'score_raw': result_text,
            'Correctness': parsed['Correctness'],
            'PersonaFit': parsed['PersonaFit'],
            'Consistency': parsed['Consistency'],
            'AffectiveTone': parsed['AffectiveTone'],
            'Depth': parsed['Depth'],
            'total': parsed['total'],
            'reason': parsed['reason'],
            'advice': parsed['advice']
        })

    # Save results
    df = pd.DataFrame(records)
    out_xlsx = os.path.join(res_dir, f"score{test_str}({MODEL_NAME} 1).xlsx")
    out_csv = os.path.join(res_dir, f"score{test_str}({MODEL_NAME} 1).csv")
    df.to_excel(out_xlsx, index=False)
    df.to_csv(out_csv, index=False, encoding='utf-8-sig')
    print(f"test{test_str} Scoring completed, saved to: {out_xlsx}")
